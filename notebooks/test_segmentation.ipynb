{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec65ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('../src')\n",
    "from gcn_models import GCN_Segmenter, GraphSAGE_Segmenter\n",
    "from grabcut_ops import GrabCutRefiner\n",
    "from graph_utils import build_superpixel_graph, iou_pixel\n",
    "from superpixel import SuperpixelExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "928e0711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Downloading images...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/oxford_pets/images.tar.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m             tar\u001b[38;5;241m.\u001b[39mextractall(data_dir)\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnnotations downloaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mdownload_oxford_pets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_oxford_pets\u001b[39m(data_dir):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124;03m\"\"\"Descarga el dataset Oxford-IIIT Pet\"\"\"\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 15\u001b[0m, in \u001b[0;36mdownload_oxford_pets\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (data_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading images...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages_tar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mopen(images_tar) \u001b[38;5;28;01mas\u001b[39;00m tar:\n\u001b[1;32m     17\u001b[0m         tar\u001b[38;5;241m.\u001b[39mextractall(data_dir)\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:251\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Handle temporary file setup.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m--> 251\u001b[0m     tfp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     tfp \u001b[38;5;241m=\u001b[39m tempfile\u001b[38;5;241m.\u001b[39mNamedTemporaryFile(delete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/oxford_pets/images.tar.gz'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "DATA_DIR = Path(\"data/oxford_pets\")\n",
    "def download_oxford_pets(data_dir):\n",
    "    \"\"\"Descarga el dataset Oxford-IIIT Pet\"\"\"\n",
    "    images_url = \"https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\"\n",
    "    masks_url = \"https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\"\n",
    "    \n",
    "    images_tar = data_dir / \"images.tar.gz\"\n",
    "    masks_tar = data_dir / \"annotations.tar.gz\"\n",
    "    \n",
    "    if not (data_dir / \"images\").exists():\n",
    "        print(\"Downloading images...\")\n",
    "        urllib.request.urlretrieve(images_url, images_tar)\n",
    "        with tarfile.open(images_tar) as tar:\n",
    "            tar.extractall(data_dir)\n",
    "        print(\"Images downloaded!\")\n",
    "    \n",
    "    if not (data_dir / \"annotations\").exists():\n",
    "        print(\"Downloading annotations...\")\n",
    "        urllib.request.urlretrieve(masks_url, masks_tar)\n",
    "        with tarfile.open(masks_tar) as tar:\n",
    "            tar.extractall(data_dir)\n",
    "        print(\"Annotations downloaded!\")\n",
    "\n",
    "download_oxford_pets(DATA_DIR)\n",
    "\n",
    "def download_oxford_pets(data_dir):\n",
    "    \"\"\"Descarga el dataset Oxford-IIIT Pet\"\"\"\n",
    "    # Asegurar que el directorio existe\n",
    "    data_dir = Path(data_dir)\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    images_url = \"https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\"\n",
    "    masks_url = \"https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\"\n",
    "    \n",
    "    images_tar = data_dir / \"images.tar.gz\"\n",
    "    masks_tar = data_dir / \"annotations.tar.gz\"\n",
    "    \n",
    "    if not (data_dir / \"images\").exists():\n",
    "        print(\"Downloading images...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(images_url, str(images_tar))\n",
    "            print(\"Extracting images...\")\n",
    "            with tarfile.open(images_tar) as tar:\n",
    "                tar.extractall(data_dir)\n",
    "            images_tar.unlink()  # Eliminar tar después de extraer\n",
    "            print(\"Images downloaded and extracted!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading images: {e}\")\n",
    "    else:\n",
    "        print(\"Images already downloaded!\")\n",
    "    \n",
    "    if not (data_dir / \"annotations\").exists():\n",
    "        print(\"Downloading annotations...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(masks_url, str(masks_tar))\n",
    "            print(\"Extracting annotations...\")\n",
    "            with tarfile.open(masks_tar) as tar:\n",
    "                tar.extractall(data_dir)\n",
    "            masks_tar.unlink()  # Eliminar tar después de extraer\n",
    "            print(\"Annotations downloaded and extracted!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading annotations: {e}\")\n",
    "    else:\n",
    "        print(\"Annotations already downloaded!\")\n",
    "\n",
    "# Descomentar para descargar\n",
    "download_oxford_pets(DATA_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d8f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetSegmentationDataset:\n",
    "    def __init__(self, data_dir, image_size=(256, 256)):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.image_size = image_size\n",
    "        self.images_dir = self.data_dir / \"images\"\n",
    "        self.masks_dir = self.data_dir / \"annotations\" / \"trimaps\"\n",
    "        \n",
    "        if self.images_dir.exists():\n",
    "            self.image_files = sorted(list(self.images_dir.glob(\"*.jpg\")))[:50]  \n",
    "        else:\n",
    "            self.image_files = []\n",
    "            print(\"Warning: Images directory not found!\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        mask_path = self.masks_dir / (img_path.stem + \".png\")\n",
    "        \n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, self.image_size)\n",
    "        \n",
    "        if mask_path.exists():\n",
    "            mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "            mask = cv2.resize(mask, self.image_size, interpolation=cv2.INTER_NEAREST)\n",
    "            mask = (mask == 1).astype(np.uint8) \n",
    "        else:\n",
    "            mask = None\n",
    "        \n",
    "        return img, mask, img_path.name\n",
    "\n",
    "def image_to_graph(img_rgb, sp_extractor, n_segments=200):\n",
    "    \"\"\"\n",
    "    Convierte imagen en grafo de superpixels\n",
    "    \"\"\"\n",
    "    segments = sp_extractor.compute(img_rgb)\n",
    "    \n",
    "    features = sp_extractor.features(img_rgb, segments)\n",
    "    \n",
    "    G, sp, node_color, centroids_norm, counts = build_superpixel_graph(\n",
    "        img_rgb, n_segments=n_segments\n",
    "    )\n",
    "    \n",
    "    edge_index = []\n",
    "    edge_weight = []\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        edge_index.append([u, v])\n",
    "        edge_index.append([v, u])\n",
    "        edge_weight.append(data['weight'])\n",
    "        edge_weight.append(data['weight'])\n",
    "    \n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_weight = torch.tensor(edge_weight, dtype=torch.float)\n",
    "    \n",
    "    x = torch.cat([\n",
    "        torch.tensor(node_color, dtype=torch.float),\n",
    "        torch.tensor(centroids_norm, dtype=torch.float),\n",
    "        torch.tensor(counts, dtype=torch.float).unsqueeze(1)\n",
    "    ], dim=1)\n",
    "    \n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_weight)\n",
    "    \n",
    "    return data, segments, G\n",
    "\n",
    "class HybridSegmenter:\n",
    "    def __init__(self, model, sp_extractor, grabcut_refiner, device='cpu'):\n",
    "        self.model = model.to(device)\n",
    "        self.sp_extractor = sp_extractor\n",
    "        self.grabcut = grabcut_refiner\n",
    "        self.device = device\n",
    "    \n",
    "    def predict(self, img_rgb, threshold=0.5, use_grabcut=True):\n",
    "        \"\"\"\n",
    "        Pipeline completo:\n",
    "        1. GCN predice en superpixels\n",
    "        2. GrabCut refina la máscara\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Crear grafo\n",
    "        graph_data, segments, G = image_to_graph(img_rgb, self.sp_extractor)\n",
    "        graph_data = graph_data.to(self.device)\n",
    "        \n",
    "        # Predicción GCN\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(graph_data)\n",
    "            probs = F.softmax(logits, dim=1)[:, 1]  # Probabilidad foreground\n",
    "        \n",
    "        # Convertir a máscara de superpixels\n",
    "        sp_mask = (probs.cpu().numpy() > threshold).astype(np.uint8)\n",
    "        \n",
    "        # Mapear a píxeles\n",
    "        pixel_mask = sp_mask[segments]\n",
    "        \n",
    "        if use_grabcut:\n",
    "            # Inicializar GrabCut desde superpixels\n",
    "            fg_ids = np.where(sp_mask == 1)[0]\n",
    "            bg_ids = np.where(sp_mask == 0)[0]\n",
    "            \n",
    "            init_mask = self.grabcut.init_from_superpixels(segments, fg_ids, bg_ids)\n",
    "            \n",
    "            # Aplicar GrabCut\n",
    "            img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
    "            refined_mask = self.grabcut.run(img_bgr, init_mask)\n",
    "            final_mask = self.grabcut.to_binary(refined_mask)\n",
    "        else:\n",
    "            final_mask = pixel_mask\n",
    "        \n",
    "        return {\n",
    "            'gcn_probs': probs.cpu().numpy(),\n",
    "            'sp_mask': sp_mask,\n",
    "            'pixel_mask': pixel_mask,\n",
    "            'final_mask': final_mask,\n",
    "            'segments': segments\n",
    "        }\n",
    "\n",
    "# %% Función de entrenamiento\n",
    "def train_gcn(model, train_data_list, epochs=20, lr=0.001, device='cpu'):\n",
    "    \"\"\"\n",
    "    Entrena el modelo GCN\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for data, y in train_data_list:\n",
    "            data = data.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(train_data_list)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# %% Preparar datos de entrenamiento (ejemplo sintético)\n",
    "def prepare_training_data(dataset, sp_extractor, num_samples=20):\n",
    "    \"\"\"\n",
    "    Prepara datos para entrenar GCN usando máscaras ground truth\n",
    "    \"\"\"\n",
    "    train_data_list = []\n",
    "    \n",
    "    for idx in range(min(num_samples, len(dataset))):\n",
    "        img, mask, name = dataset[idx]\n",
    "        \n",
    "        if mask is None:\n",
    "            continue\n",
    "        \n",
    "        # Crear grafo\n",
    "        graph_data, segments, G = image_to_graph(img, sp_extractor)\n",
    "        \n",
    "        # Etiquetar superpixels según ground truth\n",
    "        n_sp = segments.max() + 1\n",
    "        sp_labels = np.zeros(n_sp, dtype=np.long)\n",
    "        \n",
    "        for k in range(n_sp):\n",
    "            sp_pixels = (segments == k)\n",
    "            fg_ratio = mask[sp_pixels].mean()\n",
    "            sp_labels[k] = 1 if fg_ratio > 0.5 else 0\n",
    "        \n",
    "        y = torch.tensor(sp_labels, dtype=torch.long)\n",
    "        \n",
    "        train_data_list.append((graph_data, y))\n",
    "    \n",
    "    return train_data_list\n",
    "\n",
    "# %% Visualización\n",
    "def visualize_results(img, results, gt_mask=None):\n",
    "    \"\"\"\n",
    "    Visualiza resultados del pipeline híbrido\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # Imagen original\n",
    "    axes[0, 0].imshow(img)\n",
    "    axes[0, 0].set_title(\"Original Image\")\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Superpixels con predicción GCN\n",
    "    segments = results['segments']\n",
    "    sp_viz = results['sp_mask'][segments]\n",
    "    axes[0, 1].imshow(img)\n",
    "    axes[0, 1].imshow(sp_viz, alpha=0.5, cmap='jet')\n",
    "    axes[0, 1].set_title(\"GCN Superpixel Prediction\")\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Máscara píxel (GCN)\n",
    "    axes[0, 2].imshow(results['pixel_mask'], cmap='gray')\n",
    "    axes[0, 2].set_title(\"GCN Pixel Mask\")\n",
    "    axes[0, 2].axis('off')\n",
    "    \n",
    "    # Máscara final (GrabCut)\n",
    "    axes[1, 0].imshow(results['final_mask'], cmap='gray')\n",
    "    axes[1, 0].set_title(\"Final Mask (with GrabCut)\")\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Overlay final\n",
    "    axes[1, 1].imshow(img)\n",
    "    axes[1, 1].imshow(results['final_mask'], alpha=0.5, cmap='Reds')\n",
    "    axes[1, 1].set_title(\"Final Overlay\")\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    # Ground truth (si existe)\n",
    "    if gt_mask is not None:\n",
    "        axes[1, 2].imshow(gt_mask, cmap='gray')\n",
    "        axes[1, 2].set_title(\"Ground Truth\")\n",
    "        iou = iou_pixel(results['final_mask'], gt_mask)\n",
    "        axes[1, 2].text(10, 30, f\"IoU: {iou:.3f}\", \n",
    "                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    else:\n",
    "        axes[1, 2].axis('off')\n",
    "    \n",
    "    axes[1, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# %% DEMO: Pipeline completo\n",
    "def run_demo():\n",
    "    \"\"\"\n",
    "    Ejecuta demo completo del pipeline híbrido\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"GCN-GrabCut Hybrid Segmentation Demo\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Inicializar componentes\n",
    "    sp_extractor = SuperpixelExtractor(num_segments=150, compactness=10)\n",
    "    grabcut_refiner = GrabCutRefiner(iterations=5)\n",
    "    \n",
    "    # 2. Crear modelo\n",
    "    model = GCN_Segmenter(\n",
    "        in_channels=6,  # [L, a, b, y_norm, x_norm, size]\n",
    "        hidden_channels=32,\n",
    "        out_channels=2,\n",
    "        dropout=0.2\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nModel: {model.__class__.__name__}\")\n",
    "    print(f\"Parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "    \n",
    "    # 3. Cargar dataset\n",
    "    dataset = PetSegmentationDataset(DATA_DIR, image_size=(256, 256))\n",
    "    print(f\"\\nDataset size: {len(dataset)} images\")\n",
    "    \n",
    "    if len(dataset) == 0:\n",
    "        print(\"\\n⚠️  No images found! Please download the Oxford-IIIT Pet Dataset:\")\n",
    "        print(\"    Uncomment the 'download_oxford_pets(DATA_DIR)' line above\")\n",
    "        return\n",
    "    \n",
    "    # 4. Entrenar modelo (opcional, con datos sintéticos si no hay GT)\n",
    "    print(\"\\n--- Training GCN ---\")\n",
    "    train_data = prepare_training_data(dataset, sp_extractor, num_samples=10)\n",
    "    \n",
    "    if len(train_data) > 0:\n",
    "        losses = train_gcn(model, train_data, epochs=20, lr=0.001, device=DEVICE)\n",
    "        \n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(losses)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"⚠️  No training data with masks available\")\n",
    "    \n",
    "    # 5. Crear segmentador híbrido\n",
    "    hybrid = HybridSegmenter(model, sp_extractor, grabcut_refiner, device=DEVICE)\n",
    "    \n",
    "    # 6. Probar en imágenes\n",
    "    print(\"\\n--- Testing on images ---\")\n",
    "    for idx in [0, 5, 10]:  # Probar 3 imágenes\n",
    "        if idx >= len(dataset):\n",
    "            break\n",
    "        \n",
    "        img, mask, name = dataset[idx]\n",
    "        print(f\"\\nProcessing: {name}\")\n",
    "        \n",
    "        # Predicción\n",
    "        results = hybrid.predict(img, threshold=0.5, use_grabcut=True)\n",
    "        \n",
    "        # Visualizar\n",
    "        visualize_results(img, results, gt_mask=mask)\n",
    "        \n",
    "        # Métricas\n",
    "        if mask is not None:\n",
    "            iou_gcn = iou_pixel(results['pixel_mask'], mask)\n",
    "            iou_final = iou_pixel(results['final_mask'], mask)\n",
    "            print(f\"  IoU (GCN only): {iou_gcn:.3f}\")\n",
    "            print(f\"  IoU (with GrabCut): {iou_final:.3f}\")\n",
    "            print(f\"  Improvement: {(iou_final - iou_gcn):.3f}\")\n",
    "\n",
    "# %% Ejecutar demo\n",
    "if __name__ == \"__main__\":\n",
    "    run_demo()\n",
    "\n",
    "# %% Experimento: Comparar GCN vs GraphSAGE\n",
    "def compare_architectures():\n",
    "    \"\"\"\n",
    "    Compara diferentes arquitecturas de GNN\n",
    "    \"\"\"\n",
    "    sp_extractor = SuperpixelExtractor(num_segments=150, compactness=10)\n",
    "    grabcut_refiner = GrabCutRefiner(iterations=5)\n",
    "    dataset = PetSegmentationDataset(DATA_DIR, image_size=(256, 256))\n",
    "    \n",
    "    if len(dataset) == 0:\n",
    "        print(\"No images available!\")\n",
    "        return\n",
    "    \n",
    "    models = {\n",
    "        'GCN': GCN_Segmenter(in_channels=6, hidden_channels=32, out_channels=2),\n",
    "        'GraphSAGE': GraphSAGE_Segmenter(in_channels=6, hidden_channels=32, out_channels=2)\n",
    "    }\n",
    "    \n",
    "    results_comparison = {}\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"Testing: {model_name}\")\n",
    "        print('='*40)\n",
    "        \n",
    "        # Entrenar\n",
    "        train_data = prepare_training_data(dataset, sp_extractor, num_samples=10)\n",
    "        if len(train_data) > 0:\n",
    "            train_gcn(model, train_data, epochs=15, device=DEVICE)\n",
    "        \n",
    "        # Evaluar\n",
    "        hybrid = HybridSegmenter(model, sp_extractor, grabcut_refiner, device=DEVICE)\n",
    "        \n",
    "        ious = []\n",
    "        for idx in range(min(5, len(dataset))):\n",
    "            img, mask, _ = dataset[idx]\n",
    "            if mask is None:\n",
    "                continue\n",
    "            \n",
    "            results = hybrid.predict(img, use_grabcut=True)\n",
    "            iou = iou_pixel(results['final_mask'], mask)\n",
    "            ious.append(iou)\n",
    "        \n",
    "        results_comparison[model_name] = {\n",
    "            'mean_iou': np.mean(ious) if ious else 0,\n",
    "            'std_iou': np.std(ious) if ious else 0\n",
    "        }\n",
    "        \n",
    "        print(f\"Mean IoU: {results_comparison[model_name]['mean_iou']:.3f} ± \"\n",
    "              f\"{results_comparison[model_name]['std_iou']:.3f}\")\n",
    "    \n",
    "    # Visualizar comparación\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    names = list(results_comparison.keys())\n",
    "    means = [results_comparison[n]['mean_iou'] for n in names]\n",
    "    stds = [results_comparison[n]['std_iou'] for n in names]\n",
    "    \n",
    "    plt.bar(names, means, yerr=stds, capsize=5, alpha=0.7)\n",
    "    plt.ylabel('Mean IoU')\n",
    "    plt.title('Architecture Comparison')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Descomentar para ejecutar comparación\n",
    "# compare_architectures()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
